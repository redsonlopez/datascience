{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPSX2scLg4kajmziDXcUxlF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"NEAiEs5WboTr","executionInfo":{"status":"ok","timestamp":1695756257029,"user_tz":180,"elapsed":365,"user":{"displayName":"Hedson Lopes","userId":"00601403561073870653"}}},"outputs":[],"source":["import pandas as pd\n","from typing import Tuple\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","\n","class DataPrep:\n","  def __init__(self, data: pd.DataFrame) -> None:\n","    \"\"\"Inicializa a classe DataPrep com a base de dados do Titanic.\"\"\"\n","    self.data= data\n","\n","  def remover_variaveis(self) -> None:\n","    \"\"\"Remove as variáveis que não serão utilizadas pelo modelo.\"\"\"\n","    colunas_para_remover= [\n","        \"PassengerId\",\n","        \"Name\",\n","        \"Ticket\",\n","        \"Cabin\", # Variável com muitos dados faltantes\n","        \"Embarked\", # Substituídas por variáveis dummies\n","        \"SibSp\", \"Parch\" # Foram combinadas em uma nova variável\n","    ]\n","    self.data.drop(columns= colunas_para_remover, inplace= True)\n","\n","  def tratar_nulos(self) -> None:\n","    \"\"\"Faz o tratamento das variáveis nulas, imputando o valor adequado.\"\"\"\n","    self.data[\"Age\"] = self.data.groupby([\"Pclass\", \"Sex\"], group_keys= False)[\"Age\"].apply(lambda x: x.fillna(x.median()))\n","    self.data[\"Embarked\"]= self.data[\"Embarked\"].fillna(\"S\")\n","\n","  def tratar_variaveis_categoricas(self) -> None:\n","    \"\"\"Faz o tratamento das variáveis categóricas.\"\"\"\n","    sexo= {\"male\": 0, \"female\": 1} # Label Encoding\n","    self.data[\"Sex\"]= self.data[\"Sex\"].map(sexo)\n","\n","    embarked_dummies= pd.get_dummies(self.data[\"Embarked\"])\n","    self.data= pd.concat([self.data, embarked_dummies], axis= 1)\n","\n","  def dimensionar_dados(self) -> None:\n","    variaveis= self.data.drop(columns= \"Survived\")\n","    var_cols= variaveis.columns\n","    resposta= self.data[\"Survived\"]\n","\n","    scaler= MinMaxScaler()\n","    variaveis= scaler.fit_transform(variaveis)\n","    variaveis= pd.DataFrame(variaveis, columns= var_cols)\n","    self.data= pd.concat([variaveis, resposta], axis= 1)\n","\n","  def criar_variaveis(self) -> None:\n","    self.data[\"FamilySize\"]= self.data[\"SibSp\"] + self.data[\"Parch\"] + 1\n","\n","  def separa_treino_teste(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n","    \"\"\"Separa a base de dados entre conjunto de treinamento e teste.\"\"\"\n","    treino, teste= train_test_split(self.data, test_size= 0.3, random_state= 2021)\n","    return treino, teste\n","\n","  def preparar_dados(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n","    \"\"\"Executa todas as etapas de transformação de dados.\"\"\"\n","    self.tratar_nulos()\n","    self.tratar_variaveis_categoricas()\n","    self.criar_variaveis()\n","    self.remover_variaveis()\n","    self.dimensionar_dados()\n","    treino, teste= self.separa_treino_teste()\n","    return treino, teste"]}]}